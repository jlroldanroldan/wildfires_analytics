{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import re  # regular expressions\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import rasterio as rio\n",
    "from rasterio.plot import plotting_extent\n",
    "import geopandas as gpd\n",
    "import earthpy as et\n",
    "import earthpy.plot as ep\n",
    "import earthpy.spatial as es\n",
    "import earthpy.mask as em\n",
    "\n",
    "import rioxarray as rxr\n",
    "\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from queue import Queue\n",
    "\n",
    "import time\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(os.path.join(et.io.HOME, 'BD', 'BA_DATA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "d_limit = 1200 # pixel resolutino (1km) 1200 * 1200\n",
    "tem_conversion = 0.02 # convert to Kelvin temperature\n",
    "vege_fillvalue = -3000 \n",
    "vege_lowerest = -2000\n",
    "NE_fillvalue = 32767\n",
    "tem_fillvalue = 0\n",
    "radius = 50\n",
    "\n",
    "vege_len = 457 # how many 16-day files for 20 years\n",
    "tem_len = 914 # how many 8-day files for 20 years\n",
    "NE_len = 914\n",
    "thermal_len = 914\n",
    "files_one_year = 46 # how many 8-day files in a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vege_fs85 = glob('VegeData_16day/*h08v05*')\n",
    "tem_fs85 = glob('TemData_8day/*h08v05*')\n",
    "NE_fs85 = glob('NE_Data_8day/*h08v05*')\n",
    "thermal_fs85 = glob('ThermalData_8day/*h08v05*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions used for computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick any location, divide the neighborhood into several regions of interest in various directions, each region is within RADIUS distance, and ANGLE_RANGE degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sector_mask(shape,centre,radius,angle_range):\n",
    "    \"\"\"\n",
    "    Return a boolean mask for a circular sector. The start/stop angles in  \n",
    "    `angle_range` should be given in clockwise order.\n",
    "    \"\"\"\n",
    "\n",
    "    x,y = np.ogrid[:shape[0],:shape[1]]\n",
    "    cx,cy = centre\n",
    "    tmin,tmax = np.deg2rad(angle_range)\n",
    "\n",
    "    # ensure stop angle > start angle\n",
    "    if tmax < tmin:\n",
    "            tmax += 2*np.pi\n",
    "\n",
    "    # convert cartesian --> polar coordinates\n",
    "    r2 = (x-cx)*(x-cx) + (y-cy)*(y-cy)\n",
    "    theta = np.arctan2(x-cx,y-cy) - tmin\n",
    "\n",
    "    # wrap angles between 0 and 2*pi\n",
    "    theta %= (2*np.pi)\n",
    "\n",
    "    # circular mask\n",
    "    circmask = r2 <= radius*radius\n",
    "\n",
    "    # angular mask\n",
    "    anglemask = theta <= (tmax-tmin)\n",
    "\n",
    "    return circmask*anglemask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fire_intensity(matrix, row, column):\n",
    "    \"\"\"\n",
    "    Return a feature of a single pixel with row number ROW and column number COLUMN in the 1200 * 1200 matrix MATRIX.\n",
    "    Feature set is computed based on the average value in the area of a circle in one time frame.\n",
    "    \"\"\"\n",
    "    mask = sector_mask(matrix.shape, (row, column), radius, (0, 360))\n",
    "    sector = matrix[mask]\n",
    "    sum_value = np.sum(sector)\n",
    "    return sum_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vege_feature_set(matrix, row, column):\n",
    "    \"\"\"\n",
    "    Return a vegetation indices feature set of a single pixel with row number ROW and column number COLUMN \n",
    "    in the 1200 * 1200 matrix MATRIX.\n",
    "    Feature set is computed based on the average value in 10 regions in one time frame.\n",
    "    \"\"\"\n",
    "    feature_set = []\n",
    "    for i in range(10):\n",
    "        mask = sector_mask(matrix.shape, (row, column), radius, (i, i + 36))\n",
    "        sector = matrix[mask]\n",
    "        sector[:][sector[:] == vege_fillvalue] = vege_lowerest # change fillvalue\n",
    "        mean_value = np.mean(sector)\n",
    "        feature_set.append(mean_value)\n",
    "    return feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_thermal_feature_set(matrix, row, column):\n",
    "    \"\"\"\n",
    "    Return a thermal anomalies feature set of a single pixel with row number ROW and column number COLUMN \n",
    "    in the 1200 * 1200 matrix MATRIX.\n",
    "    Feature set is computed based on the sum of value in 10 regions in one time frame.\n",
    "    \"\"\"\n",
    "    feature_set = []\n",
    "    for i in range(10):\n",
    "        mask = sector_mask(matrix.shape, (row, column), radius, (i, i + 36))\n",
    "        sector = matrix[mask]\n",
    "        # normalize to 0 and 1\n",
    "        sector[:][sector[:] < 7] = 0\n",
    "        sector[:][sector[:] >= 7] = 1\n",
    "        sum_value = np.sum(sector)\n",
    "        feature_set.append(sum_value)\n",
    "    return feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tem_feature_set(matrix, row, column):\n",
    "    \"\"\"\n",
    "    Return a surface temperature feature set of a single pixel with row number ROW and column number COLUMN \n",
    "    in the 1200 * 1200 matrix MATRIX.\n",
    "    Feature set is computed based on the mean of value in 10 regions in one time frame.\n",
    "    \"\"\"\n",
    "    feature_set = []\n",
    "    for i in range(10):\n",
    "        mask = sector_mask(matrix.shape, (row, column), radius, (i, i + 36))\n",
    "        sector = matrix[mask]\n",
    "        mean_value = np.mean(sector)\n",
    "        feature_set.append(mean_value)\n",
    "    return feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_NE_feature_set(matrix, row, column):\n",
    "    \"\"\"\n",
    "    Return a NE feature set of a single pixel with row number ROW and column number COLUMN \n",
    "    in the 1200 * 1200 matrix MATRIX.\n",
    "    Feature set is computed based on the mean of value in 10 regions in one time frame.\n",
    "    \"\"\"\n",
    "    feature_set = []\n",
    "    for i in range(10):\n",
    "        mask = sector_mask(matrix.shape, (row, column), radius, (i, i + 36))\n",
    "        sector = matrix[mask]\n",
    "        mean_value = np.mean(sector)\n",
    "        feature_set.append(mean_value)\n",
    "    return feature_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebin(m, shape):\n",
    "    \"\"\"\n",
    "    Reshape the input matrix A to the shape SHAPE.\n",
    "    \"\"\"\n",
    "    sh = shape[0],m.shape[0]//shape[0],shape[1],m.shape[1]//shape[1]\n",
    "    return m.reshape(sh).mean(-1).mean(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def land_mask(file):\n",
    "    \"\"\"\n",
    "    Compute land mask from QA field in thermal data.\n",
    "    Used for enforcing random sampling on land pixels.\n",
    "    \"\"\"\n",
    "    all_bands = []\n",
    "    with rio.open(file) as dataset:\n",
    "        for name in dataset.subdatasets:\n",
    "            if re.search(\"QA\", name):\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                    all_bands.append(subdataset.read(1))\n",
    "    fire_modis = np.stack(all_bands)\n",
    "    fire_matrix = fire_modis[0].reshape(d_limit,d_limit)\n",
    "    for i in range(d_limit):\n",
    "        for j in range(d_limit):\n",
    "            k = fire_matrix[i][j]\n",
    "            b1 = k >> 0 & 1\n",
    "            b2 = k >> 1 & 1\n",
    "            if b1 != b2:\n",
    "                fire_matrix[i][j] = 1\n",
    "            else:\n",
    "                fire_matrix[i][j] = 0\n",
    "    return fire_matrix\n",
    "lm = land_mask(thermal_fs85[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_position():\n",
    "    \"\"\"\n",
    "    Get a random position on the map, excluding edge cases.\n",
    "    \"\"\"\n",
    "    random_indexR = np.random.randint(60, d_limit - 60)\n",
    "    random_indexC = np.random.randint(60, d_limit - 60)\n",
    "    return (random_indexR, random_indexC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute libsvm style datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features_all(all_fire_fns, file_id, fire_fns, tem_fns, vege_fns, ne_fns, num_file, radius, sample_count):\n",
    "    \"\"\"\n",
    "    Compute target sets, geographical feature sets, time series feature sets for libsvm style for every two 8-day files.\n",
    "    Target sets are computed based on thermal anomalies data from FIRE_FNS files.\n",
    "    Target sets: Y -> 1.0/0.0\n",
    "    Feature fire intensity based on thermal anomalies data from FIRE_FNS files;\n",
    "    Feature temperature based on surface temperature data from TEM_FNS files;\n",
    "    Feature vegetation based on vegetation indices data from VEGE_FNS files;\n",
    "    Feature ne based on net evaporation data from NE_FNS files.\n",
    "    Feature sets: X -> fire intensity(10), temperature(10), vegetation(10), net evaporation(10), past fire intensity(5)\n",
    "    Every 16 days, randomly sample SMAMPLE_COUNT number of pixels with fire, and SMAMPLE_COUNT number of pixels without fire.\n",
    "        if there are less than SMAPLE_COUNT number of pixels with fire, sample all the fire pixels.\n",
    "    ALL_FIRE_FNS and FILE_ID are used for tracing past files for time series features\n",
    "    FILE_ID should be no smaller than 115 (5 years)\n",
    "    \"\"\"\n",
    "    \n",
    "    # sds names for hdf files\n",
    "    fire_sds1 = \"FireMask\"\n",
    "    tem_sds1 = \"LST_Day\"\n",
    "    vege_sds1 = \"EVI\"\n",
    "    ne_sds1 = \":ET_500m\"\n",
    "    ne_sds2 = \"PET\"\n",
    "   \n",
    "    # get fire mask\n",
    "    \n",
    "    sds1 = \"FireMask\"\n",
    "    \n",
    "    file_count = num_file // 2\n",
    "    fire_positions = []\n",
    "  \n",
    "    # compute fire_combined_matrix\n",
    "    \n",
    "    f1_bands = []\n",
    "    f2_bands = []\n",
    "    \n",
    "    # open two files in a round\n",
    "    with rio.open(fire_fns[0]) as dataset:\n",
    "        for name in dataset.subdatasets:\n",
    "            if re.search(fire_sds1, name):\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                    f1_bands.append(subdataset.read(1))\n",
    "    f1_modis = np.stack(f1_bands)\n",
    "    f1_matrix = f1_modis[0].reshape(d_limit,d_limit)\n",
    "    \n",
    "    with rio.open(fire_fns[1]) as dataset:\n",
    "        for name in dataset.subdatasets:\n",
    "            if re.search(fire_sds1, name):\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                    f2_bands.append(subdataset.read(1))\n",
    "    f2_modis = np.stack(f2_bands)\n",
    "    f2_matrix = f2_modis[0].reshape(d_limit,d_limit)\n",
    "    \n",
    "    # combine two matrices\n",
    "    fire_combined_matrix = (f1_matrix + f2_matrix) / 2\n",
    "    for r in range(60, 1140):\n",
    "        for c in range(60, 1140):\n",
    "            if (fire_combined_matrix[r][c] >= 7):\n",
    "                 fire_positions.append([r,c])\n",
    "    \n",
    "    # compute tem_combined_matrix\n",
    "    \n",
    "    f1_bands = []\n",
    "    f2_bands = []\n",
    "    with rio.open(tem_fns[0]) as dataset:\n",
    "        for name in dataset.subdatasets:\n",
    "            if re.search(tem_sds1, name):\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                    f1_bands.append(subdataset.read(1))\n",
    "    f1_modis = np.stack(f1_bands)\n",
    "    f1_matrix = f1_modis[0].reshape(d_limit,d_limit)\n",
    "\n",
    "    with rio.open(tem_fns[1]) as dataset:\n",
    "        for name in dataset.subdatasets:\n",
    "            if re.search(tem_sds1, name):\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                    f2_bands.append(subdataset.read(1))\n",
    "    f2_modis = np.stack(f2_bands)\n",
    "    f2_matrix = f2_modis[0].reshape(d_limit,d_limit)\n",
    "    \n",
    "    # combine two matrices\n",
    "    tem_combined_matrix = (f1_matrix + f2_matrix) / 2\n",
    "    \n",
    "    # compute vege_combined_matrix\n",
    "    \n",
    "    all_bands = []\n",
    "    with rio.open(vege_fns) as dataset:\n",
    "        for name in dataset.subdatasets:\n",
    "            if re.search(vege_sds1, name):\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                    all_bands.append(subdataset.read(1))\n",
    "    vege_modis = np.stack(all_bands)\n",
    "    vege_matrix = vege_modis[0].reshape(d_limit,d_limit)\n",
    "        \n",
    "    # compute ne_combined_matrix    \n",
    "    \n",
    "    f1_bands = []\n",
    "    f2_bands = []\n",
    "    f1_bands_se = []\n",
    "    f2_bands_se = []\n",
    "    \n",
    "    # open two files in a round\n",
    "    with rio.open(ne_fns[0]) as dataset:\n",
    "        for name in dataset.subdatasets:\n",
    "            if re.search(ne_sds1, name):\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                    f1_bands.append(subdataset.read(1))\n",
    "            if re.search(ne_sds2, name):\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                    f1_bands_se.append(subdataset.read(1))\n",
    "    f1_modis = np.stack(f1_bands)\n",
    "    f1_matrix = rebin(f1_modis[0], (d_limit,d_limit))\n",
    "    f1_modis_se = np.stack(f1_bands_se)\n",
    "    f1_matrix_se = rebin(f1_modis_se[0], (d_limit,d_limit))\n",
    "    \n",
    "    with rio.open(ne_fns[1]) as dataset:\n",
    "        for name in dataset.subdatasets:\n",
    "            if re.search(ne_sds1, name):\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                    f2_bands.append(subdataset.read(1))\n",
    "            if re.search(ne_sds2, name):\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                    f2_bands_se.append(subdataset.read(1))\n",
    "    f2_modis = np.stack(f2_bands)\n",
    "    f2_matrix = rebin(f2_modis[0], (d_limit,d_limit))\n",
    "    f2_modis_se = np.stack(f2_bands_se)\n",
    "    f2_matrix_se = rebin(f2_modis_se[0], (d_limit,d_limit))\n",
    "    \n",
    "    # combine two matrices\n",
    "    f1_matrix = f1_matrix_se - f1_matrix\n",
    "    f2_matrix = f2_matrix_se - f2_matrix\n",
    "    ne_combined_matrix = (f1_matrix + f2_matrix) / 2\n",
    "        \n",
    "    all_feature_sets = []\n",
    "    all_target_sets = []\n",
    "    random_positions = []\n",
    "    \n",
    "    # random samples   \n",
    "    for i in range(sample_count):\n",
    "        p = random_position()\n",
    "        while True:\n",
    "            \n",
    "            # check for non-fire land pixel sample\n",
    "            if (p not in fire_positions) and lm[p[0]][p[1]] == 1:\n",
    "                random_positions.append(p)\n",
    "                break;\n",
    "            else:\n",
    "                p = random_position()\n",
    "                \n",
    "        # now have a good random position\n",
    "        r = p[0]\n",
    "        c = p[1]\n",
    "        features = []\n",
    "        \n",
    "        thermal_feature_set = compute_thermal_feature_set(fire_combined_matrix, r, c)\n",
    "        features.append(thermal_feature_set)\n",
    "        \n",
    "        tem_feature_set = compute_thermal_feature_set(tem_combined_matrix, r, c)\n",
    "        features.append(tem_feature_set)\n",
    "        \n",
    "        vege_feature_set = compute_thermal_feature_set(vege_matrix, r, c)\n",
    "        features.append(vege_feature_set)\n",
    "        \n",
    "        ne_feature_set = compute_thermal_feature_set(ne_combined_matrix, r, c)\n",
    "        features.append(ne_feature_set)\n",
    "        \n",
    "        flat_list = [item for sublist in features for item in sublist]\n",
    "        all_feature_sets.append(flat_list)\n",
    "        \n",
    "        # normalize FIRE_MASK to 1 or 0\n",
    "        if (fire_combined_matrix[r][c] >= 7):\n",
    "            all_target_sets.append(1)\n",
    "        else:\n",
    "            all_target_sets.append(0)\n",
    "    \n",
    "    # fire positions\n",
    "    final_fire_positions = []\n",
    "    count = 0\n",
    "    if sample_count > len(fire_positions):\n",
    "        count = len(fire_positions)\n",
    "    else:\n",
    "        count = sample_count\n",
    "    for i in range(count):\n",
    "        p = np.random.randint(0, len(fire_positions))\n",
    "        while True:\n",
    "            if fire_positions[p] not in final_fire_positions:\n",
    "                final_fire_positions.append(fire_positions[p])\n",
    "                break;\n",
    "            else:\n",
    "                p = np.random.randint(0, len(fire_positions))\n",
    "                \n",
    "    for i in final_fire_positions:\n",
    "        r = i[0]\n",
    "        c = i[1]\n",
    "        features = []\n",
    "        \n",
    "        thermal_feature_set = compute_thermal_feature_set(fire_combined_matrix, r, c)\n",
    "        features.append(thermal_feature_set)\n",
    "        \n",
    "        tem_feature_set = compute_thermal_feature_set(tem_combined_matrix, r, c)\n",
    "        features.append(tem_feature_set)\n",
    "        \n",
    "        vege_feature_set = compute_thermal_feature_set(vege_matrix, r, c)\n",
    "        features.append(vege_feature_set)\n",
    "        \n",
    "        ne_feature_set = compute_thermal_feature_set(ne_combined_matrix, r, c)\n",
    "        features.append(ne_feature_set)\n",
    "        \n",
    "        flat_list = [item for sublist in features for item in sublist]\n",
    "        all_feature_sets.append(flat_list)\n",
    "        \n",
    "        # normalize FIRE_MASK to 1 or 0\n",
    "        if (fire_combined_matrix[r][c] >= 7):\n",
    "            all_target_sets.append(1)\n",
    "        else:\n",
    "            all_target_sets.append(0)\n",
    "\n",
    "    # compute time series features\n",
    "    # assume there exists data five years ago\n",
    "    time_features_arr = time_series_features(all_fire_fns, file_id, radius, random_positions, final_fire_positions)\n",
    "    time_features = time_features_arr.tolist()\n",
    "    \n",
    "    # merge geographic and time series features\n",
    "    final_all_feature_sets = [geo + time for geo, time in zip(all_feature_sets, time_features)]\n",
    "    \n",
    "    return (all_target_sets, final_all_feature_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_features(all_fire_fns, file_id, radius, random_positions, fire_positions):\n",
    "    \"\"\"\n",
    "    Compute time_series_features for a 16-day combined file for locations: RANDOM_POSITIONS and FIRE_POSITIONS\n",
    "    \"\"\"\n",
    "    rp_count = len(random_positions)\n",
    "    fp_count = len(fire_positions)\n",
    "    total_count = rp_count + fp_count\n",
    "    time_features = np.zeros((total_count, 5))\n",
    "    \n",
    "    # compute past fire intensity up to 5 years ago\n",
    "    for year in range(1, 6):\n",
    "        past_file_id = file_id - year * files_one_year\n",
    "        if past_file_id < 0:\n",
    "            print(\"cannot find enough historical files\")\n",
    "            return\n",
    "        past_file = all_fire_fns[past_file_id]\n",
    "        f_bands = []\n",
    "        with rio.open(past_file) as dataset:\n",
    "            for name in dataset.subdatasets:\n",
    "                if re.search(\"FireMask\", name):\n",
    "                    with rio.open(name) as subdataset:\n",
    "                        modis_meta = subdataset.profile\n",
    "                        f_bands.append(subdataset.read(1))\n",
    "        f_modis = np.stack(f_bands)\n",
    "        f_matrix = f_modis[0]\n",
    "        f_matrix[:][f_matrix[:] < 7] = 0\n",
    "        f_matrix[:][f_matrix[:] >= 7] = 1\n",
    "        for i in range(rp_count):\n",
    "            position = random_positions[i]\n",
    "            r = position[0]\n",
    "            c = position[1]\n",
    "            fire_intensity = compute_fire_intensity(f_matrix, r, c)\n",
    "            time_features[i][year-1] = fire_intensity\n",
    "        for j in range(fp_count):\n",
    "            position = fire_positions[j]\n",
    "            r = position[0]\n",
    "            c = position[1]\n",
    "            fire_intensity = compute_fire_intensity(f_matrix, r, c)\n",
    "            time_features[j+rp_count][year-1] = fire_intensity\n",
    "    return time_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a libsvm file for every 16 day data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From 5th year to 20th year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(115, 290):\n",
    "    result = compute_features_all(thermal_fs85, 2*i, thermal_fs85[2*i:(2*i+2)], tem_fs85[2*i:(2*i+2)], vege_fs85[i], NE_fs85[2*i:(2*i+2)], 2, 50, 10)\n",
    "    dump_svmlight_file(result[1],result[0],os.path.join(\"svms/sample%s\" % i),zero_based=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(290, 457):\n",
    "    result = compute_features_all(thermal_fs85, 2*i, thermal_fs85[2*i:(2*i+2)], tem_fs85[2*i:(2*i+2)], vege_fs85[i], NE_fs85[2*i:(2*i+2)], 2, 50, 10)\n",
    "    dump_svmlight_file(result[1],result[0],os.path.join(\"svms/sample%s\" % i),zero_based=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all the libsvm files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cat * > svms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Models using PySpark on Dumbo clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the final libsvm file and build models on Dumbo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Load the data stored in LIBSVM format as a DataFrame.\n",
    "data = spark.read.format(\"libsvm\").load(\"./svms\")\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "\n",
    "treeModel = model.stages[2]\n",
    "# summary only\n",
    "print(treeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Test Error = 0.00839092"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Test Error = 0.00252525"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Test Error = 0.00593472"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Test Error = 0.00388727"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Test Error = 0.00507099"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Accuracy: 99. 483617%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "data = spark.read.format(\"libsvm\").load(\"./svms\")\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"predictedLabel\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "rfModel = model.stages[2]\n",
    "print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Test Error = 0.00945274"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Test Error = 0.00691017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Test Error = 0.00838678"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Test Error = 0.00853414"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Test Error = 0.0128395"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Test Error = 0.00550826"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Accuracy: 99. 1394735%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient-boosted tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "data = spark.read.format(\"libsvm\").load(\"./svms\")\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a GBT model.\n",
    "gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=10)\n",
    "\n",
    "# Chain indexers and GBT in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "gbtModel = model.stages[2]\n",
    "print(gbtModel)  # summary only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Test Error = 0.00732422"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Test Error = 0.00496278"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Test Error = 0.00767386"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Test Error = 0.00447984"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Test Error = 0.00729217"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Accuracy: 99.3653426%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-vs-Rest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression, OneVsRest\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# load data file.\n",
    "inputData = spark.read.format(\"libsvm\") \\\n",
    "    .load(\"./svms\")\n",
    "\n",
    "# generate the train/test split.\n",
    "(train, test) = inputData.randomSplit([0.7, 0.3])\n",
    "\n",
    "# instantiate the base classifier.\n",
    "lr = LogisticRegression(maxIter=10, tol=1E-6, fitIntercept=True)\n",
    "\n",
    "# instantiate the One Vs Rest Classifier.\n",
    "ovr = OneVsRest(classifier=lr)\n",
    "\n",
    "# train the multiclass model.\n",
    "ovrModel = ovr.fit(train)\n",
    "\n",
    "# score the model on test data.\n",
    "predictions = ovrModel.transform(test)\n",
    "\n",
    "# obtain evaluator.\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "\n",
    "# compute the classification error on test data.\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Test Error = 0.268806"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Test Error = 0.286676"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Test Error = 0.275571"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Test Error = 0.268966"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Test Error = 0.258654"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Accuracy: 72.82654%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Load training data\n",
    "data = spark.read.format(\"libsvm\") \\\n",
    "    .load(\"./svms\")\n",
    "\n",
    "# Split the data into train and test\n",
    "splits = data.randomSplit([0.7, 0.3], 1234)\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "\n",
    "# train the model\n",
    "model = nb.fit(train)\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = model.transform(test)\n",
    "predictions.show()\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Test set accuracy = 0.663537549407"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Test set accuracy = 0.669216061185"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Test set accuracy = 0.666833416708"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Test set accuracy = 0.641062801932"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Test set accuracy = 0.66087388282"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Accuracy: 66.03047424104%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Load the data stored in LIBSVM format as a DataFrame.\n",
    "data = spark.read.format(\"libsvm\").load(\"./svms\")\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeRegressor(featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# Chain indexer and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, dt])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "treeModel = model.stages[1]\n",
    "# summary only\n",
    "print(treeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Root Mean Squared Error (RMSE) on test data = 0.0696107"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Root Mean Squared Error (RMSE) on test data = 0.068184"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Root Mean Squared Error (RMSE) on test data = 0.0794518"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Root Mean Squared Error (RMSE) on test data = 0.0834209"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Root Mean Squared Error (RMSE) on test data = 0.0839181"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average RMSE: 0.0769171"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "data = spark.read.format(\"libsvm\").load(\"./svms\")\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestRegressor(featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# Chain indexer and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, rf])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "rfModel = model.stages[1]\n",
    "print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Root Mean Squared Error (RMSE) on test data = 0.112305"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Root Mean Squared Error (RMSE) on test data = 0.110443"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Root Mean Squared Error (RMSE) on test data = 0.100557"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Root Mean Squared Error (RMSE) on test data = 0.12123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Root Mean Squared Error (RMSE) on test data = 0.0929676"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average RMSE: 0.10750052"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient-boosted tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "data = spark.read.format(\"libsvm\").load(\"./svms\")\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a GBT model.\n",
    "gbt = GBTRegressor(featuresCol=\"indexedFeatures\", maxIter=10)\n",
    "\n",
    "# Chain indexer and GBT in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, gbt])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "gbtModel = model.stages[1]\n",
    "print(gbtModel)  # summary only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Root Mean Squared Error (RMSE) on test data = 0.0848031"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Root Mean Squared Error (RMSE) on test data = 0.0602163"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Root Mean Squared Error (RMSE) on test data = 0.0714394"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Root Mean Squared Error (RMSE) on test data = 0.041476"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Root Mean Squared Error (RMSE) on test data = 0.085556"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average RMSE: 0.06869816"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
