{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.earthdatascience.org/courses/use-data-open-source-python/hierarchical-data-formats-hdf/open-MODIS-hdf4-files-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import re  # regular expressions\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import rasterio as rio\n",
    "from rasterio.plot import plotting_extent\n",
    "import geopandas as gpd\n",
    "import earthpy as et\n",
    "import earthpy.plot as ep\n",
    "import earthpy.spatial as es\n",
    "import earthpy.mask as em\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(os.path.join(et.io.HOME, 'nyu', 'rbda_project_data'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a path to the pre-fire MODIS h4 data\n",
    "vegetation_path = os.path.join(\"vegetation_indices_11_28\",\n",
    "                               \"MOD13A2.A2019113.h08v05.006.2019129235845.hdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View dataset metadata\n",
    "with rio.open(vegetation_path) as dataset:\n",
    "    print(dataset)\n",
    "    hdf4_meta = dataset.meta\n",
    "\n",
    "# Notice that there are metadata at the highest level of the file\n",
    "hdf4_meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all of the subdatasets in the data\n",
    "with rio.open(vegetation_path) as dataset:\n",
    "    crs = dataset.read_crs()\n",
    "    for name in dataset.subdatasets:\n",
    "        print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list to append arrays (of all type of data)\n",
    "vegetation_data = []\n",
    "vegetation_names = []\n",
    "\n",
    "# Open the precipitation HDF5 file \n",
    "with rio.open(vegetation_path) as dataset:\n",
    "    \n",
    "    # loop through each subdataset in HDF5 file\n",
    "    for name in dataset.subdatasets:\n",
    "        \n",
    "        # Open the subdataset \n",
    "        with rio.open(name) as subdataset:\n",
    "            modis_meta = subdataset.profile\n",
    "            \n",
    "            # Read data as a  2 dimensional array and append to list\n",
    "            vegetation_data.append(subdataset.read(1))\n",
    "            vegetation_names.append(name);\n",
    "#             np.savetxt(str(name)[-10:-1] + \".csv\", subdataset.read(1), delimiter=\",\")\n",
    "\n",
    "\n",
    "vegetation_data_stacked = np.stack(vegetation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vegetation_data_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ep.plot_bands(vegetation_data_stacked,\n",
    "#               scale=False)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot MODIS RGB\n",
    "# ep.plot_rgb(vegetation_data_stacked,\n",
    "#             rgb=[0, 3, 2],\n",
    "#             title='RGB Image of MODIS Data',\n",
    "#             stretch=True,\n",
    "#             figsize=(7, 7))\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process multiple files in a directory\n",
    "https://realpython.com/working-with-files-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store name of files in file_names list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = os.scandir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names  = []\n",
    "with os.scandir('../rbda_project_data/vegetation_indices_all_time_testing/') as entries:\n",
    "    for entry in entries:\n",
    "        file_names.append(entry.name)\n",
    "#         print(entry.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process multiple HDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.scandir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with os.scandir('./vegetation_indices_all_time_testing/') as entries:\n",
    "#     for entry in entries:\n",
    "#         file_names.append(entry.name)\n",
    "#         print(entry.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_files = []\n",
    "for file in file_names: \n",
    "    paths_to_files.append(os.path.join(\"vegetation_indices_all_time_testing\",\n",
    "                               str(file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all of the subdatasets in the data\n",
    "for path_to_file in paths_to_files:\n",
    "    with rio.open(path_to_file) as dataset:\n",
    "        crs = dataset.read_crs()\n",
    "        for name in dataset.subdatasets:\n",
    "            print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Used paths_to_files[0] to process the first HDF file of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list to append arrays (of all type of data)\n",
    "vegetation_data_test = []\n",
    "vegetation_names_test = []\n",
    "\n",
    "# Open the precipitation HDF5 file \n",
    "with rio.open(paths_to_files[0]) as dataset:\n",
    "    \n",
    "    # loop through each subdataset in HDF5 file\n",
    "    for name in dataset.subdatasets:\n",
    "        \n",
    "        # Open the subdataset \n",
    "        with rio.open(name) as subdataset:\n",
    "            modis_meta = subdataset.profile\n",
    "            \n",
    "            # Read data as a  2 dimensional array and append to list\n",
    "            vegetation_data_test.append(subdataset.read(1))\n",
    "            vegetation_names_test.append(name);\n",
    "#             np.savetxt(str(name)[-10:-1] + \".csv\", subdataset.read(1), delimiter=\",\")\n",
    "\n",
    "\n",
    "# vegetation_data_stacked = np.stack(vegetation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## all NVDI test \n",
    "# all_nvdi = []\n",
    "\n",
    "# for path_to_file in paths_to_files:\n",
    "    \n",
    "#     with rio.open(path_to_file) as dataset:\n",
    "        \n",
    "#         for name in dataset.subdatasets:\n",
    "#             if re.search(\"NDVI.\\_1$\", name):\n",
    "            \n",
    "#                 with rio.open(name) as subdataset:\n",
    "#                     modis_meta = subdataset.profile\n",
    "                    \n",
    "#                     all_nvdi.append(subdataset.read(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegetation_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegetation_names_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract only NDVI subdataset from first hdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list to append arrays (of all type of data)\n",
    "ndvi_and_quality = []\n",
    "ndvi_and_quality_names = []\n",
    "\n",
    "# Open the precipitation HDF5 file \n",
    "with rio.open(paths_to_files[0]) as dataset:\n",
    "    \n",
    "    # loop through each subdataset in HDF5 file\n",
    "    for name in dataset.subdatasets:\n",
    "        \n",
    "        # Use regular expression to identify if subdataset has b0 in the name (the bands)\n",
    "        if re.search(\"NDVI$\", name):\n",
    "\n",
    "            # Open the subdataset \n",
    "            with rio.open(name) as subdataset:\n",
    "                modis_meta = subdataset.profile\n",
    "\n",
    "                # Read data as a  2 dimensional array and append to list\n",
    "                ndvi_and_quality.append(subdataset.read(1))\n",
    "                ndvi_and_quality_names.append(name);\n",
    "    #             np.savetxt(str(name)[-10:-1] + \".csv\", subdataset.read(1), delimiter=\",\")\n",
    "                np.savetxt(ndvi_and_quality_names[-1][54:95] + \"_ndvi\" + \".csv\", subdataset.read(1), delimiter=\",\")\n",
    "        \n",
    "# vegetation_data_stacked = np.stack(vegetation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_and_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_and_quality_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_and_quality_names[0][54:95] + \"_ndvi\" + \".csv\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
