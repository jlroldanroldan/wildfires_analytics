{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import re  # regular expressions\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import rasterio as rio\n",
    "from rasterio.plot import plotting_extent\n",
    "import geopandas as gpd\n",
    "import earthpy as et\n",
    "import earthpy.plot as ep\n",
    "import earthpy.spatial as es\n",
    "import earthpy.mask as em\n",
    "\n",
    "import rioxarray as rxr\n",
    "\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from queue import Queue\n",
    "\n",
    "import time\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(os.path.join(et.io.HOME, 'nyu', 'rbda_project_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "d_limit = 1200\n",
    "tem_conversion = 0.02 # convert to Kelvin temperature\n",
    "vege_fillvalue = -3000\n",
    "vege_lowerest = -2000\n",
    "NE_fillvalue = 32767\n",
    "tem_fillvalue = 0\n",
    "radius = 50\n",
    "\n",
    "vege_len = 457\n",
    "tem_len = 914\n",
    "NE_len = 914\n",
    "thermal_len = 914\n",
    "files_one_year = 46 # how many 8-day files in a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vege_fs84 = glob('VegeData_16day/*h08v04*')\n",
    "vege_fs85 = glob('VegeData_16day/*h08v05*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tem_fs84 = glob('TemData_8day/*h08v04*')\n",
    "tem_fs85 = glob('TemData_8day/*h08v05*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NE_fs84 = glob('NE_Data_8day/*h08v04*')\n",
    "NE_fs85 = glob('NE_Data_8day/*h08v05*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thermal_fs84 = glob('ThermalData_8day/*h08v04*')\n",
    "thermal_fs85 = glob('ThermalData_8day/*h08v05*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "914"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NE_fs85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(NE_fs84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "914"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tem_fs85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick any location, divide the neighborhood into 10 regions of interest in various directions, each region is within 50 km, 36 degree and 50 km sector as a region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sector_mask(shape,centre,radius,angle_range):\n",
    "    \"\"\"\n",
    "    Return a boolean mask for a circular sector. The start/stop angles in  \n",
    "    `angle_range` should be given in clockwise order.\n",
    "    \"\"\"\n",
    "\n",
    "    x,y = np.ogrid[:shape[0],:shape[1]]\n",
    "    cx,cy = centre\n",
    "    tmin,tmax = np.deg2rad(angle_range)\n",
    "\n",
    "    # ensure stop angle > start angle\n",
    "    if tmax < tmin:\n",
    "            tmax += 2*np.pi\n",
    "\n",
    "    # convert cartesian --> polar coordinates\n",
    "    r2 = (x-cx)*(x-cx) + (y-cy)*(y-cy)\n",
    "    theta = np.arctan2(x-cx,y-cy) - tmin\n",
    "\n",
    "    # wrap angles between 0 and 2*pi\n",
    "    theta %= (2*np.pi)\n",
    "\n",
    "    # circular mask\n",
    "    circmask = r2 <= radius*radius\n",
    "\n",
    "    # angular mask\n",
    "    anglemask = theta <= (tmax-tmin)\n",
    "\n",
    "    return circmask*anglemask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fire_intensity(matrix, row, column):\n",
    "    \"\"\"\n",
    "    Return a feature of a single pixel with row number ROW and column number COLUMN in the 1200 * 1200 matrix MATRIX.\n",
    "    Feature set is computed based on the average value in the area of a circle in one time frame from FILENAMES.\n",
    "    \"\"\"\n",
    "    mask = sector_mask(matrix.shape, (row, column), radius, (0, 360))\n",
    "    sector = matrix[mask]\n",
    "    sum_value = np.sum(sector)\n",
    "    return sum_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vege_feature_set(matrix, row, column):\n",
    "    \"\"\"\n",
    "    Return a vegetation indices feature set of a single pixel with row number ROW and column number COLUMN \n",
    "    in the 1200 * 1200 matrix MATRIX.\n",
    "    Feature set is computed based on the average value in 10 regions in one time frame from FILENAMES.\n",
    "    \"\"\"\n",
    "    feature_set = []\n",
    "    for i in range(10):\n",
    "        mask = sector_mask(matrix.shape, (row, column), radius, (i, i + 36))\n",
    "        sector = matrix[mask]\n",
    "        sector[:][sector[:] == vege_fillvalue] = vege_lowerest # change fillvalue\n",
    "        mean_value = np.mean(sector)\n",
    "        feature_set.append(mean_value)\n",
    "    return feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_thermal_feature_set(matrix, row, column):\n",
    "    \"\"\"\n",
    "    Return a thermal anomalies feature set of a single pixel with row number ROW and column number COLUMN \n",
    "    in the 1200 * 1200 matrix MATRIX.\n",
    "    Feature set is computed based on the sum of value in 10 regions in one time frame from FILENAMES.\n",
    "    \"\"\"\n",
    "    feature_set = []\n",
    "    for i in range(10):\n",
    "        mask = sector_mask(matrix.shape, (row, column), radius, (i, i + 36))\n",
    "        sector = matrix[mask]\n",
    "        sector[:][sector[:] < 7] = 0\n",
    "        sector[:][sector[:] >= 7] = 1\n",
    "        sum_value = np.sum(sector)\n",
    "        feature_set.append(sum_value)\n",
    "    return feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tem_feature_set(matrix, row, column):\n",
    "    \"\"\"\n",
    "    Return a surface temperature feature set of a single pixel with row number ROW and column number COLUMN \n",
    "    in the 1200 * 1200 matrix MATRIX.\n",
    "    Feature set is computed based on the mean of value in 10 regions in one time frame from FILENAMES.\n",
    "    \"\"\"\n",
    "    feature_set = [] # use array instead\n",
    "    for i in range(10):\n",
    "        mask = sector_mask(matrix.shape, (row, column), radius, (i, i + 36))\n",
    "        sector = matrix[mask]\n",
    "        #sector = sector[sector[:] != 0] # drop fillvalue\n",
    "        mean_value = np.mean(sector)\n",
    "        feature_set.append(mean_value)\n",
    "    return feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_NE_feature_set(matrix, row, column):\n",
    "    \"\"\"\n",
    "    Return a NE feature set of a single pixel with row number ROW and column number COLUMN \n",
    "    in the 1200 * 1200 matrix MATRIX.\n",
    "    Feature set is computed based on the mean of value in 10 regions in one time frame from FILENAMES.\n",
    "    \"\"\"\n",
    "    feature_set = []\n",
    "    for i in range(10):\n",
    "        mask = sector_mask(matrix.shape, (row, column), radius, (i, i + 36))\n",
    "        sector = matrix[mask]\n",
    "        mean_value = np.mean(sector)\n",
    "        feature_set.append(mean_value)\n",
    "    return feature_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process 16-day hdf file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16-day for vegetation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vege_features(file, sds, fill_value, new_value, radius):\n",
    "    \"\"\"\n",
    "    Return feature sets of all pixels in the file FILE.\n",
    "    SDS is NDVI or EVI.\n",
    "    \n",
    "    \"\"\"\n",
    "    all_bands = []\n",
    "    with rio.open(file) as dataset:\n",
    "        for name in dataset.subdatasets:\n",
    "            if re.search(sds, name):\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                    all_bands.append(subdataset.read(1))\n",
    "    vege_modis = np.stack(all_bands)\n",
    "    vege_matrix = vege_modis[0].reshape(d_limit,d_limit)\n",
    "    feature_sets = np.zeros((d_limit, d_limit))\n",
    "    for r in range(d_limit):\n",
    "        for c in range(d_limit):\n",
    "            temp = compute_feature_set(vege_martrix, fill_value, new_value, r, c)\n",
    "            feature_sets[r][c] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vege_features(filenames, num_file, sds, fill_value, new_value, radius):\n",
    "    \"\"\"\n",
    "    Return vegetation indice feature sets for all files in FILENAMES\n",
    "    \"\"\"\n",
    "    all_feature_sets = np.zeros((num_file, d_limit, d_limit))\n",
    "    \n",
    "    index = 0\n",
    "    \n",
    "    for file in filenames:\n",
    "        temp = vege_features(file, sds, file_value, new_value, radius)\n",
    "        all_feature_sets[index] = temp\n",
    "        index += 1\n",
    "    return all_feature_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebin(m, shape):\n",
    "    \"\"\"\n",
    "    Reshape the input matrix A to the shape SHAPE.\n",
    "    \"\"\"\n",
    "    sh = shape[0],m.shape[0]//shape[0],shape[1],m.shape[1]//shape[1]\n",
    "    return m.reshape(sh).mean(-1).mean(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process 8-day files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8-day for thermal_data, tem_data and NE_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NE_Data_8day/MOD16A2.A2017353.h08v05.006.2018005092948.hdf',\n",
       " 'NE_Data_8day/MOD16A2.A2001169.h08v05.006.2017071225056.hdf',\n",
       " 'NE_Data_8day/MOD16A2.A2003065.h08v05.006.2017098044059.hdf',\n",
       " 'NE_Data_8day/MOD16A2.A2005273.h08v05.006.2017075093315.hdf']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NE_fs85[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NE_Data_8day/MOD16A2.A2007001.h08v05.006.2017080103206.hdf',\n",
       " 'NE_Data_8day/MOD16A2.A2004009.h08v05.006.2017095025704.hdf',\n",
       " 'NE_Data_8day/MOD16A2.A2004353.h08v05.006.2017104192927.hdf',\n",
       " 'NE_Data_8day/MOD16A2.A2013337.h08v05.006.2017106215311.hdf']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NE_fs85[4:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features_8day(filenames, num_file, radius, feature_type):\n",
    "    \"\"\"\n",
    "    Combine every two 8-day files to compute feature sets. There are in total NUM_FILES in filenames. Used for 8-day datasets.\n",
    "    Use a queue to help iterate through every two files.\n",
    "    Input filenames is the result from using glob command\n",
    "    Result is a 3d np array with all the SDS features using 10-region method\n",
    "    \"\"\"\n",
    "    print(1)\n",
    "    sds1 = None\n",
    "    sds2 = None\n",
    "    if feature_type == \"thermal\":\n",
    "        sds1 = \"FireMask\"\n",
    "    elif feature_type == \"tem\":\n",
    "        sds1 = \"LST_Day\"\n",
    "    elif feature_type == \"NE\":\n",
    "        sds1 = \":ET_500m\"\n",
    "        sds2 = \"PET\"\n",
    "    else:\n",
    "        print(\"No such feature for 8-day\")\n",
    "        return\n",
    "    print(2)\n",
    "    file_count = num_file // 2\n",
    "    all_feature_sets = np.zeros((file_count, 1080, 1080, 10))\n",
    "    q = Queue(1000)\n",
    "    print(3)\n",
    "    for filename in filenames:\n",
    "        q.put(filename)\n",
    "    print(4)\n",
    "    for i in range (file_count):\n",
    "        f1 = q.get()\n",
    "        f2 = q.get()\n",
    "        f1_bands = []\n",
    "        f2_bands = []\n",
    "        f1_bands_se = []\n",
    "        f2_bands_se = []\n",
    "        # open two files in a round\n",
    "        with rio.open(f1) as dataset:\n",
    "            for name in dataset.subdatasets:\n",
    "                if re.search(sds1, name):\n",
    "                    with rio.open(name) as subdataset:\n",
    "                        modis_meta = subdataset.profile\n",
    "                        f1_bands.append(subdataset.read(1))\n",
    "                if feature_type == \"NE\":\n",
    "                    if re.search(sds2, name):\n",
    "                        with rio.open(name) as subdataset:\n",
    "                            modis_meta = subdataset.profile\n",
    "                            f1_bands_se.append(subdataset.read(1))\n",
    "        f1_modis = np.stack(f1_bands)\n",
    "        f1_matrix = f1_modis[0].reshape(d_limit,d_limit)\n",
    "        if feature_type == \"NE\":\n",
    "            f1_modis_se = np.stack(f1_bands_se)\n",
    "            f1_matrix_se = f1_modis_se[0].reshape(d_limit,d_limit)\n",
    "        print(5)\n",
    "        with rio.open(f2) as dataset:\n",
    "            for name in dataset.subdatasets:\n",
    "                if re.search(sds1, name):\n",
    "                    with rio.open(name) as subdataset:\n",
    "                        modis_meta = subdataset.profile\n",
    "                        f2_bands.append(subdataset.read(1))\n",
    "                if feature_type == \"NE\":\n",
    "                    if re.search(sds2, name):\n",
    "                        with rio.open(name) as subdataset:\n",
    "                            modis_meta = subdataset.profile\n",
    "                            f2_bands_se.append(subdataset.read(1))\n",
    "        f2_modis = np.stack(f2_bands)\n",
    "        f2_matrix = f2_modis[0].reshape(d_limit,d_limit)\n",
    "        if feature_type == \"NE\":\n",
    "            f2_modis_se = np.stack(f2_bands_se)\n",
    "            f2_matrix_se = f2_modis_se[0].reshape(d_limit,d_limit)\n",
    "        # combine two matrices\n",
    "        if feature_type == \"NE\":\n",
    "            f1_matrix = f1_matrix_se - f1_matrix\n",
    "            f2_matrix = f2_matrix_se - f2_matrix\n",
    "        combined_matrix = (f1_matrix + f2_matrix) / 2\n",
    "        if feature_type == \"tem\":\n",
    "            combined_matrix = combined_matrix * tem_conversion\n",
    "        feature_sets = np.zeros((1080, 1080))\n",
    "        print(6)\n",
    "        for r in range(60, 1140):\n",
    "            for c in range(60, 1140):\n",
    "                if feature_type == \"thermal\":\n",
    "                    temp = compute_thermal_feature_set(combined_matrix, r, c)\n",
    "                elif feature_type == \"tem\":\n",
    "                    temp = compute_tem_feature_set(combined_matrix, r, c)\n",
    "                    print(temp)\n",
    "                elif feature_type == \"vege\":\n",
    "                    temp = compute_vege_feature_set(combined_matrix, r, c)\n",
    "                else:\n",
    "                    temp = compute_NE_feature_set(combined_matrix, r, c)\n",
    "                feature_sets[r][c] = np.copy(temp)\n",
    "        \n",
    "        all_feature_sets[i] = np.copy(feature_sets)\n",
    "        return all_feature_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def land_mask(file):\n",
    "    # compute land mask from QA field in thermal data\n",
    "    all_bands = []\n",
    "    with rio.open(file) as dataset:\n",
    "        for name in dataset.subdatasets:\n",
    "            if re.search(\"QA\", name):\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                    all_bands.append(subdataset.read(1))\n",
    "    fire_modis = np.stack(all_bands)\n",
    "    fire_matrix = fire_modis[0].reshape(d_limit,d_limit)\n",
    "    for i in range(d_limit):\n",
    "        for j in range(d_limit):\n",
    "            k = fire_matrix[i][j]\n",
    "            b1 = k >> 0 & 1\n",
    "            b2 = k >> 1 & 1\n",
    "            if b1 != b2:\n",
    "                fire_matrix[i][j] = 1\n",
    "            else:\n",
    "                fire_matrix[i][j] = 0\n",
    "    return fire_matrix\n",
    "lm = land_mask(thermal_fs85[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_position():\n",
    "    random_indexR = np.random.randint(60, 1140)\n",
    "    random_indexC = np.random.randint(60, 1140)\n",
    "    return (random_indexR, random_indexC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(559, 337)\n"
     ]
    }
   ],
   "source": [
    "a = random_position()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features_all(all_fire_fns, file_id, fire_fns, tem_fns, vege_fns, ne_fns, num_file, radius, sample_count):\n",
    "    \"\"\"\n",
    "    X = fire::tem::vege::ne  each row (4 * 10)\n",
    "    Y = 1/0\n",
    "    (fire_positions + random 20 samples) rows for X\n",
    "    all_fire_fns and file_id are used for time series features\n",
    "    file_id is no smaller than 230 (5 years)\n",
    "    \"\"\"\n",
    "    #print(1)\n",
    "    fire_sds1 = \"FireMask\"\n",
    "    tem_sds1 = \"LST_Day\"\n",
    "    vege_sds1 = \"EVI\"\n",
    "    ne_sds1 = \":ET_500m\"\n",
    "    ne_sds2 = \"PET\"\n",
    "    #print(2)\n",
    "    \n",
    "    # get fire mask\n",
    "    #print(1)\n",
    "    sds1 = \"FireMask\"\n",
    "    #print(2)\n",
    "    file_count = num_file // 2\n",
    "    fire_positions = []\n",
    "    #q = Queue(file_count)\n",
    "    #print(3)\n",
    "    #for filename in fire_fns:\n",
    "        #q.put(filename)\n",
    "    #print(4)\n",
    "    \n",
    "    # compute fire_combined_matrix\n",
    "    #f1 = q.get()\n",
    "    #f2 = q.get()\n",
    "    f1_bands = []\n",
    "    f2_bands = []\n",
    "    # open two files in a round\n",
    "    with rio.open(fire_fns[0]) as dataset:\n",
    "        for name in dataset.subdatasets:\n",
    "            if re.search(fire_sds1, name):\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                    f1_bands.append(subdataset.read(1))\n",
    "    f1_modis = np.stack(f1_bands)\n",
    "    f1_matrix = f1_modis[0].reshape(d_limit,d_limit)\n",
    "    #print(5)\n",
    "    with rio.open(fire_fns[1]) as dataset:\n",
    "        for name in dataset.subdatasets:\n",
    "            if re.search(fire_sds1, name):\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                    f2_bands.append(subdataset.read(1))\n",
    "    f2_modis = np.stack(f2_bands)\n",
    "    f2_matrix = f2_modis[0].reshape(d_limit,d_limit)\n",
    "    # combine two matrices\n",
    "    fire_combined_matrix = (f1_matrix + f2_matrix) / 2\n",
    "    for r in range(60, 1140):\n",
    "        for c in range(60, 1140):\n",
    "            if (fire_combined_matrix[r][c] >= 7):\n",
    "                 fire_positions.append([r,c])\n",
    "    #print(\"fire_mask\")\n",
    "    #feature_count = len(fire_positions) * 4 * 10\n",
    "    #all_feature_sets = np.zeros((1080, 1080, 40))\n",
    "    #print(len(fire_positions))\n",
    "    \n",
    "    # compute tem_combined_matrix\n",
    "    f1_bands = []\n",
    "    f2_bands = []\n",
    "    with rio.open(tem_fns[0]) as dataset:\n",
    "        for name in dataset.subdatasets:\n",
    "            if re.search(tem_sds1, name):\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                    f1_bands.append(subdataset.read(1))\n",
    "    f1_modis = np.stack(f1_bands)\n",
    "    f1_matrix = f1_modis[0].reshape(d_limit,d_limit)\n",
    "    #print(5)\n",
    "    with rio.open(tem_fns[1]) as dataset:\n",
    "        for name in dataset.subdatasets:\n",
    "            if re.search(tem_sds1, name):\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                    f2_bands.append(subdataset.read(1))\n",
    "    f2_modis = np.stack(f2_bands)\n",
    "    f2_matrix = f2_modis[0].reshape(d_limit,d_limit)\n",
    "    # combine two matrices\n",
    "    tem_combined_matrix = (f1_matrix + f2_matrix) / 2\n",
    "    \n",
    "    \n",
    "    # compute vege_combined_matrix\n",
    "    all_bands = []\n",
    "    with rio.open(vege_fns) as dataset:\n",
    "        for name in dataset.subdatasets:\n",
    "            if re.search(vege_sds1, name):\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                    all_bands.append(subdataset.read(1))\n",
    "    vege_modis = np.stack(all_bands)\n",
    "    vege_matrix = vege_modis[0].reshape(d_limit,d_limit)\n",
    "        \n",
    "        \n",
    "    # compute ne_combined_matrix    \n",
    "    f1_bands = []\n",
    "    f2_bands = []\n",
    "    f1_bands_se = []\n",
    "    f2_bands_se = []\n",
    "    # open two files in a round\n",
    "    with rio.open(ne_fns[0]) as dataset:\n",
    "        for name in dataset.subdatasets:\n",
    "            if re.search(ne_sds1, name):\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                    f1_bands.append(subdataset.read(1))\n",
    "            if re.search(ne_sds2, name):\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                    f1_bands_se.append(subdataset.read(1))\n",
    "    f1_modis = np.stack(f1_bands)\n",
    "    #print(f1_modis.shape)\n",
    "    f1_matrix = rebin(f1_modis[0], (d_limit,d_limit))\n",
    "    f1_modis_se = np.stack(f1_bands_se)\n",
    "    f1_matrix_se = rebin(f1_modis_se[0], (d_limit,d_limit))\n",
    "    #print(5)\n",
    "    with rio.open(ne_fns[1]) as dataset:\n",
    "        for name in dataset.subdatasets:\n",
    "            if re.search(ne_sds1, name):\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                    f2_bands.append(subdataset.read(1))\n",
    "            if re.search(ne_sds2, name):\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                    f2_bands_se.append(subdataset.read(1))\n",
    "    f2_modis = np.stack(f2_bands)\n",
    "    f2_matrix = rebin(f2_modis[0], (d_limit,d_limit))\n",
    "    f2_modis_se = np.stack(f2_bands_se)\n",
    "    f2_matrix_se = rebin(f2_modis_se[0], (d_limit,d_limit))\n",
    "    # combine two matrices\n",
    "    f1_matrix = f1_matrix_se - f1_matrix\n",
    "    f2_matrix = f2_matrix_se - f2_matrix\n",
    "    ne_combined_matrix = (f1_matrix + f2_matrix) / 2\n",
    "        \n",
    "    all_feature_sets = []\n",
    "    all_target_sets = []\n",
    "    random_positions = []\n",
    "    \n",
    "    # random samples   \n",
    "    for i in range(sample_count):\n",
    "        #print(i)\n",
    "        p = random_position()\n",
    "        while True:\n",
    "            if (p not in fire_positions) and lm[p[0]][p[1]] == 1:\n",
    "                random_positions.append(p)\n",
    "                break;\n",
    "            else:\n",
    "                p = random_position()\n",
    "                \n",
    "        # now have a good random position\n",
    "        r = p[0]\n",
    "        c = p[1]\n",
    "        features = []\n",
    "        thermal_feature_set = compute_thermal_feature_set(fire_combined_matrix, r, c)\n",
    "        features.append(thermal_feature_set)\n",
    "        tem_feature_set = compute_thermal_feature_set(tem_combined_matrix, r, c)\n",
    "        features.append(tem_feature_set)\n",
    "        vege_feature_set = compute_thermal_feature_set(vege_matrix, r, c)\n",
    "        features.append(vege_feature_set)\n",
    "        ne_feature_set = compute_thermal_feature_set(ne_combined_matrix, r, c)\n",
    "        features.append(ne_feature_set)\n",
    "        flat_list = [item for sublist in features for item in sublist]\n",
    "        all_feature_sets.append(flat_list)\n",
    "        if (fire_combined_matrix[r][c] >= 7):\n",
    "            all_target_sets.append(1)\n",
    "        else:\n",
    "            all_target_sets.append(0)\n",
    "    \n",
    "    # fire positions\n",
    "    final_fire_positions = []\n",
    "    count = 0\n",
    "    if sample_count > len(fire_positions):\n",
    "        count = len(fire_positions)\n",
    "    else:\n",
    "        count = sample_count\n",
    "    for i in range(count):\n",
    "        #print(i)\n",
    "        p = np.random.randint(0, len(fire_positions))\n",
    "        while True:\n",
    "            if fire_positions[p] not in final_fire_positions:\n",
    "                final_fire_positions.append(fire_positions[p])\n",
    "                break;\n",
    "            else:\n",
    "                p = np.random.randint(0, len(fire_positions))\n",
    "    for i in final_fire_positions:\n",
    "        #print(i)\n",
    "        r = i[0]\n",
    "        c = i[1]\n",
    "        features = []\n",
    "        thermal_feature_set = compute_thermal_feature_set(fire_combined_matrix, r, c)\n",
    "        features.append(thermal_feature_set)\n",
    "        tem_feature_set = compute_thermal_feature_set(tem_combined_matrix, r, c)\n",
    "        features.append(tem_feature_set)\n",
    "        vege_feature_set = compute_thermal_feature_set(vege_matrix, r, c)\n",
    "        features.append(vege_feature_set)\n",
    "        ne_feature_set = compute_thermal_feature_set(ne_combined_matrix, r, c)\n",
    "        features.append(ne_feature_set)\n",
    "        flat_list = [item for sublist in features for item in sublist]\n",
    "        all_feature_sets.append(flat_list)\n",
    "        if (fire_combined_matrix[r][c] >= 7):\n",
    "            all_target_sets.append(1)\n",
    "        else:\n",
    "            all_target_sets.append(0)\n",
    "\n",
    "    # compute time series features\n",
    "    # assume there exists data five years ago\n",
    "    time_features_arr = time_series_features(all_fire_fns, file_id, radius, random_positions, final_fire_positions)\n",
    "    time_features = time_features_arr.tolist()\n",
    "    \n",
    "    # merge geographic and time series features\n",
    "    final_all_feature_sets = [geo + time for geo, time in zip(all_feature_sets, time_features)]\n",
    "    \n",
    "    return (all_target_sets, final_all_feature_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_features(all_fire_fns, file_id, radius, random_positions, fire_positions):\n",
    "    # compute time_series_features for a 16 day combined file\n",
    "    # file_id is no smaller than 230 (5 years)\n",
    "    rp_count = len(random_positions)\n",
    "    fp_count = len(fire_positions)\n",
    "    total_count = rp_count + fp_count\n",
    "    time_features = np.zeros((total_count, 5))\n",
    "    for year in range(1, 6):\n",
    "        past_file_id = file_id - year * files_one_year\n",
    "        if past_file_id < 0:\n",
    "            print(\"out of index\")\n",
    "            return\n",
    "        past_file = all_fire_fns[past_file_id]\n",
    "        f_bands = []\n",
    "        with rio.open(past_file) as dataset:\n",
    "            for name in dataset.subdatasets:\n",
    "                if re.search(\"FireMask\", name):\n",
    "                    with rio.open(name) as subdataset:\n",
    "                        modis_meta = subdataset.profile\n",
    "                        f_bands.append(subdataset.read(1))\n",
    "        f_modis = np.stack(f_bands)\n",
    "        f_matrix = f_modis[0]\n",
    "        f_matrix[:][f_matrix[:] < 7] = 0\n",
    "        f_matrix[:][f_matrix[:] >= 7] = 1\n",
    "        for i in range(rp_count):\n",
    "            position = random_positions[i]\n",
    "            r = position[0]\n",
    "            c = position[1]\n",
    "            fire_intensity = compute_fire_intensity(f_matrix, r, c)\n",
    "            time_features[i][year-1] = fire_intensity\n",
    "        for j in range(fp_count):\n",
    "            position = fire_positions[j]\n",
    "            r = position[0]\n",
    "            c = position[1]\n",
    "            fire_intensity = compute_fire_intensity(f_matrix, r, c)\n",
    "            time_features[j+rp_count][year-1] = fire_intensity\n",
    "    return time_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = []\n",
    "a = [1,2,3]\n",
    "b = [4,5,6]\n",
    "c = [7,8,9]\n",
    "final.append(a)\n",
    "final.append(b)\n",
    "final.append(c)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 5], [1, 2, 3, 4, 6]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[1,2,3,4],[1,2,3,4]]\n",
    "b = [[5], [6]]\n",
    "[x+y for x,y in zip(a,b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
    "test[:][test[:] < 7] = 0\n",
    "test[:][test[:] >= 7] = 1\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.083026\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "result1 = compute_features_all(thermal_fs85, 240, thermal_fs85[240:242], tem_fs85[240:242], vege_fs85[240], NE_fs85[240:242], 2, 50, 10)\n",
    "end = time.clock()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [[0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   197.0,\n",
       "   169.0,\n",
       "   169.0,\n",
       "   164.0,\n",
       "   162.0,\n",
       "   156.0,\n",
       "   154.0,\n",
       "   151.0,\n",
       "   145.0,\n",
       "   152.0,\n",
       "   206,\n",
       "   179,\n",
       "   178,\n",
       "   173,\n",
       "   169,\n",
       "   164,\n",
       "   162,\n",
       "   159,\n",
       "   153,\n",
       "   160,\n",
       "   15.0,\n",
       "   10.0,\n",
       "   9.0,\n",
       "   9.0,\n",
       "   9.0,\n",
       "   8.0,\n",
       "   8.0,\n",
       "   8.0,\n",
       "   8.0,\n",
       "   9.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   809.0,\n",
       "   783.0,\n",
       "   782.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   787.0,\n",
       "   784.0,\n",
       "   785.0,\n",
       "   803.0,\n",
       "   809,\n",
       "   783,\n",
       "   782,\n",
       "   784,\n",
       "   784,\n",
       "   784,\n",
       "   787,\n",
       "   784,\n",
       "   785,\n",
       "   803,\n",
       "   790.0,\n",
       "   763.0,\n",
       "   763.0,\n",
       "   765.0,\n",
       "   765.0,\n",
       "   765.0,\n",
       "   770.0,\n",
       "   767.0,\n",
       "   770.0,\n",
       "   790.0,\n",
       "   10.0,\n",
       "   17.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   11.0],\n",
       "  [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   809.0,\n",
       "   783.0,\n",
       "   782.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   787.0,\n",
       "   784.0,\n",
       "   785.0,\n",
       "   803.0,\n",
       "   809,\n",
       "   783,\n",
       "   782,\n",
       "   784,\n",
       "   784,\n",
       "   784,\n",
       "   787,\n",
       "   784,\n",
       "   785,\n",
       "   803,\n",
       "   809.0,\n",
       "   783.0,\n",
       "   782.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   787.0,\n",
       "   784.0,\n",
       "   785.0,\n",
       "   803.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   809.0,\n",
       "   783.0,\n",
       "   782.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   787.0,\n",
       "   784.0,\n",
       "   785.0,\n",
       "   803.0,\n",
       "   809,\n",
       "   783,\n",
       "   782,\n",
       "   784,\n",
       "   784,\n",
       "   784,\n",
       "   787,\n",
       "   784,\n",
       "   785,\n",
       "   803,\n",
       "   766.0,\n",
       "   748.0,\n",
       "   747.0,\n",
       "   756.0,\n",
       "   759.0,\n",
       "   762.0,\n",
       "   768.0,\n",
       "   767.0,\n",
       "   770.0,\n",
       "   791.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   809.0,\n",
       "   783.0,\n",
       "   782.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   787.0,\n",
       "   784.0,\n",
       "   785.0,\n",
       "   803.0,\n",
       "   809,\n",
       "   783,\n",
       "   782,\n",
       "   784,\n",
       "   784,\n",
       "   784,\n",
       "   787,\n",
       "   784,\n",
       "   785,\n",
       "   803,\n",
       "   803.0,\n",
       "   777.0,\n",
       "   776.0,\n",
       "   778.0,\n",
       "   778.0,\n",
       "   778.0,\n",
       "   781.0,\n",
       "   778.0,\n",
       "   779.0,\n",
       "   797.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   809.0,\n",
       "   783.0,\n",
       "   782.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   787.0,\n",
       "   784.0,\n",
       "   785.0,\n",
       "   803.0,\n",
       "   809,\n",
       "   783,\n",
       "   782,\n",
       "   784,\n",
       "   784,\n",
       "   784,\n",
       "   787,\n",
       "   784,\n",
       "   785,\n",
       "   803,\n",
       "   74.0,\n",
       "   66.0,\n",
       "   62.0,\n",
       "   61.0,\n",
       "   63.0,\n",
       "   66.0,\n",
       "   64.0,\n",
       "   66.0,\n",
       "   69.0,\n",
       "   79.0,\n",
       "   0.0,\n",
       "   3.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   809.0,\n",
       "   783.0,\n",
       "   782.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   787.0,\n",
       "   784.0,\n",
       "   785.0,\n",
       "   803.0,\n",
       "   809,\n",
       "   783,\n",
       "   782,\n",
       "   784,\n",
       "   784,\n",
       "   784,\n",
       "   787,\n",
       "   784,\n",
       "   785,\n",
       "   803,\n",
       "   808.0,\n",
       "   782.0,\n",
       "   781.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   787.0,\n",
       "   784.0,\n",
       "   785.0,\n",
       "   803.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   809.0,\n",
       "   783.0,\n",
       "   782.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   787.0,\n",
       "   784.0,\n",
       "   785.0,\n",
       "   803.0,\n",
       "   667,\n",
       "   644,\n",
       "   647,\n",
       "   655,\n",
       "   662,\n",
       "   667,\n",
       "   676,\n",
       "   680,\n",
       "   686,\n",
       "   708,\n",
       "   527.0,\n",
       "   497.0,\n",
       "   492.0,\n",
       "   495.0,\n",
       "   497.0,\n",
       "   495.0,\n",
       "   495.0,\n",
       "   495.0,\n",
       "   496.0,\n",
       "   518.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   52.0,\n",
       "   0.0],\n",
       "  [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   809.0,\n",
       "   783.0,\n",
       "   782.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   787.0,\n",
       "   784.0,\n",
       "   785.0,\n",
       "   803.0,\n",
       "   809,\n",
       "   783,\n",
       "   782,\n",
       "   784,\n",
       "   784,\n",
       "   784,\n",
       "   787,\n",
       "   784,\n",
       "   785,\n",
       "   803,\n",
       "   698.0,\n",
       "   692.0,\n",
       "   692.0,\n",
       "   699.0,\n",
       "   702.0,\n",
       "   708.0,\n",
       "   714.0,\n",
       "   716.0,\n",
       "   719.0,\n",
       "   738.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   3.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   809.0,\n",
       "   783.0,\n",
       "   782.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   787.0,\n",
       "   784.0,\n",
       "   785.0,\n",
       "   803.0,\n",
       "   808,\n",
       "   782,\n",
       "   781,\n",
       "   783,\n",
       "   784,\n",
       "   784,\n",
       "   787,\n",
       "   784,\n",
       "   785,\n",
       "   803,\n",
       "   803.0,\n",
       "   777.0,\n",
       "   776.0,\n",
       "   778.0,\n",
       "   778.0,\n",
       "   778.0,\n",
       "   781.0,\n",
       "   778.0,\n",
       "   779.0,\n",
       "   797.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   809.0,\n",
       "   783.0,\n",
       "   782.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   787.0,\n",
       "   784.0,\n",
       "   785.0,\n",
       "   803.0,\n",
       "   807,\n",
       "   781,\n",
       "   779,\n",
       "   781,\n",
       "   781,\n",
       "   781,\n",
       "   784,\n",
       "   781,\n",
       "   782,\n",
       "   800,\n",
       "   792.0,\n",
       "   767.0,\n",
       "   766.0,\n",
       "   768.0,\n",
       "   768.0,\n",
       "   768.0,\n",
       "   771.0,\n",
       "   768.0,\n",
       "   769.0,\n",
       "   786.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   3.0,\n",
       "   0.0,\n",
       "   1.0],\n",
       "  [2.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   809.0,\n",
       "   783.0,\n",
       "   782.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   787.0,\n",
       "   784.0,\n",
       "   785.0,\n",
       "   803.0,\n",
       "   803,\n",
       "   777,\n",
       "   776,\n",
       "   778,\n",
       "   778,\n",
       "   778,\n",
       "   781,\n",
       "   777,\n",
       "   778,\n",
       "   795,\n",
       "   763.0,\n",
       "   737.0,\n",
       "   735.0,\n",
       "   736.0,\n",
       "   735.0,\n",
       "   735.0,\n",
       "   738.0,\n",
       "   734.0,\n",
       "   735.0,\n",
       "   752.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   3.0,\n",
       "   0.0,\n",
       "   3.0],\n",
       "  [13.0,\n",
       "   6.0,\n",
       "   6.0,\n",
       "   6.0,\n",
       "   6.0,\n",
       "   6.0,\n",
       "   6.0,\n",
       "   6.0,\n",
       "   6.0,\n",
       "   8.0,\n",
       "   809.0,\n",
       "   783.0,\n",
       "   782.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   787.0,\n",
       "   784.0,\n",
       "   785.0,\n",
       "   803.0,\n",
       "   805,\n",
       "   779,\n",
       "   778,\n",
       "   780,\n",
       "   780,\n",
       "   780,\n",
       "   783,\n",
       "   780,\n",
       "   781,\n",
       "   798,\n",
       "   787.0,\n",
       "   759.0,\n",
       "   757.0,\n",
       "   757.0,\n",
       "   755.0,\n",
       "   752.0,\n",
       "   754.0,\n",
       "   749.0,\n",
       "   748.0,\n",
       "   764.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   3.0,\n",
       "   0.0,\n",
       "   1.0],\n",
       "  [8.0,\n",
       "   3.0,\n",
       "   3.0,\n",
       "   3.0,\n",
       "   3.0,\n",
       "   3.0,\n",
       "   3.0,\n",
       "   3.0,\n",
       "   3.0,\n",
       "   4.0,\n",
       "   809.0,\n",
       "   783.0,\n",
       "   782.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   787.0,\n",
       "   784.0,\n",
       "   785.0,\n",
       "   803.0,\n",
       "   809,\n",
       "   783,\n",
       "   782,\n",
       "   784,\n",
       "   784,\n",
       "   784,\n",
       "   787,\n",
       "   784,\n",
       "   785,\n",
       "   803,\n",
       "   806.0,\n",
       "   780.0,\n",
       "   779.0,\n",
       "   781.0,\n",
       "   781.0,\n",
       "   781.0,\n",
       "   784.0,\n",
       "   781.0,\n",
       "   782.0,\n",
       "   800.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   3.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [10.0,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   4.0,\n",
       "   6.0,\n",
       "   809.0,\n",
       "   783.0,\n",
       "   782.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   787.0,\n",
       "   784.0,\n",
       "   785.0,\n",
       "   803.0,\n",
       "   809,\n",
       "   783,\n",
       "   782,\n",
       "   784,\n",
       "   784,\n",
       "   784,\n",
       "   787,\n",
       "   784,\n",
       "   785,\n",
       "   803,\n",
       "   806.0,\n",
       "   780.0,\n",
       "   779.0,\n",
       "   781.0,\n",
       "   780.0,\n",
       "   781.0,\n",
       "   784.0,\n",
       "   781.0,\n",
       "   782.0,\n",
       "   800.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   3.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [6.0,\n",
       "   2.0,\n",
       "   2.0,\n",
       "   2.0,\n",
       "   2.0,\n",
       "   2.0,\n",
       "   2.0,\n",
       "   2.0,\n",
       "   2.0,\n",
       "   4.0,\n",
       "   809.0,\n",
       "   783.0,\n",
       "   782.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   787.0,\n",
       "   784.0,\n",
       "   785.0,\n",
       "   803.0,\n",
       "   806,\n",
       "   780,\n",
       "   779,\n",
       "   781,\n",
       "   781,\n",
       "   781,\n",
       "   784,\n",
       "   781,\n",
       "   782,\n",
       "   800,\n",
       "   792.0,\n",
       "   766.0,\n",
       "   766.0,\n",
       "   769.0,\n",
       "   769.0,\n",
       "   768.0,\n",
       "   771.0,\n",
       "   766.0,\n",
       "   767.0,\n",
       "   783.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   3.0,\n",
       "   0.0,\n",
       "   1.0],\n",
       "  [3.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   809.0,\n",
       "   783.0,\n",
       "   782.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   787.0,\n",
       "   784.0,\n",
       "   785.0,\n",
       "   803.0,\n",
       "   806,\n",
       "   780,\n",
       "   779,\n",
       "   781,\n",
       "   781,\n",
       "   781,\n",
       "   784,\n",
       "   780,\n",
       "   781,\n",
       "   799,\n",
       "   792.0,\n",
       "   767.0,\n",
       "   765.0,\n",
       "   766.0,\n",
       "   766.0,\n",
       "   764.0,\n",
       "   767.0,\n",
       "   762.0,\n",
       "   763.0,\n",
       "   778.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   3.0,\n",
       "   0.0,\n",
       "   1.0],\n",
       "  [13.0,\n",
       "   6.0,\n",
       "   6.0,\n",
       "   6.0,\n",
       "   6.0,\n",
       "   6.0,\n",
       "   6.0,\n",
       "   6.0,\n",
       "   6.0,\n",
       "   9.0,\n",
       "   809.0,\n",
       "   783.0,\n",
       "   782.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   787.0,\n",
       "   784.0,\n",
       "   785.0,\n",
       "   803.0,\n",
       "   806,\n",
       "   780,\n",
       "   779,\n",
       "   781,\n",
       "   780,\n",
       "   780,\n",
       "   783,\n",
       "   780,\n",
       "   781,\n",
       "   799,\n",
       "   790.0,\n",
       "   764.0,\n",
       "   762.0,\n",
       "   763.0,\n",
       "   762.0,\n",
       "   760.0,\n",
       "   762.0,\n",
       "   757.0,\n",
       "   756.0,\n",
       "   770.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   3.0,\n",
       "   0.0,\n",
       "   1.0],\n",
       "  [2.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   809.0,\n",
       "   783.0,\n",
       "   782.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   787.0,\n",
       "   784.0,\n",
       "   785.0,\n",
       "   803.0,\n",
       "   806,\n",
       "   780,\n",
       "   779,\n",
       "   781,\n",
       "   781,\n",
       "   781,\n",
       "   784,\n",
       "   781,\n",
       "   782,\n",
       "   800,\n",
       "   791.0,\n",
       "   766.0,\n",
       "   766.0,\n",
       "   768.0,\n",
       "   768.0,\n",
       "   768.0,\n",
       "   771.0,\n",
       "   767.0,\n",
       "   768.0,\n",
       "   784.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   3.0,\n",
       "   0.0,\n",
       "   1.0],\n",
       "  [3.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   809.0,\n",
       "   783.0,\n",
       "   782.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   784.0,\n",
       "   787.0,\n",
       "   784.0,\n",
       "   785.0,\n",
       "   803.0,\n",
       "   809,\n",
       "   783,\n",
       "   782,\n",
       "   784,\n",
       "   784,\n",
       "   784,\n",
       "   787,\n",
       "   784,\n",
       "   785,\n",
       "   803,\n",
       "   806.0,\n",
       "   780.0,\n",
       "   779.0,\n",
       "   781.0,\n",
       "   781.0,\n",
       "   781.0,\n",
       "   784.0,\n",
       "   781.0,\n",
       "   783.0,\n",
       "   801.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   4.0,\n",
       "   0.0,\n",
       "   0.0]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(115, 117):\n",
    "    result = compute_features_all(thermal_fs85, 2*i, thermal_fs85[2*i:(2*i+2)], tem_fs85[2*i:(2*i+2)], vege_fs85[i], NE_fs85[2*i:(2*i+2)], 2, 50, 10)\n",
    "    dump_svmlight_file(result[1],result[0],os.path.join(\"svms/sample%s\" % i),zero_based=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 115 - 290 ,  290 - 457"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-c5741ea3a0d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m457\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m458\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_features_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthermal_fs85\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthermal_fs85\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtem_fs85\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvege_fs85\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNE_fs85\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdump_svmlight_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"svms/sample%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mzero_based\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(80, 270):\n",
    "    result = compute_features_all(thermal_fs85, 2*i, thermal_fs85[2*i:(2*i+2)], tem_fs85[2*i:(2*i+2)], vege_fs85[i], NE_fs85[2*i:(2*i+2)], 2, 50, 10)\n",
    "    dump_svmlight_file(result[1],result[0],os.path.join(\"svms/sample%s\" % i),zero_based=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while os.path.exists(\"sample%s.xml\" % i):\n",
    "    i += 1\n",
    "\n",
    "fh = open(\"sample%s.xml\" % i, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
